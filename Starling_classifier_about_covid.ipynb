{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages & Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "import simpledorff\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import  LlamaForCausalLM, LlamaTokenizer, pipeline\n",
    "import transformers\n",
    "\n",
    "import torch\n",
    "from torch import cuda, bfloat16, manual_seed\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.clear_autocast_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "\n",
    "# go one level up in the directory\n",
    "os.chdir(\"/data/storage100gb5/NOS\")\n",
    "\n",
    "huggingface_cache_dir = 'model'\n",
    "\n",
    "# change huggingface cache\n",
    "os.environ['TRANSFORMERS_CACHE'] = huggingface_cache_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model_id = 'berkeley-nest/Starling-LM-7B-alpha'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "# begin initializing HF items, need auth token for these\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=huggingface_cache_dir\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    cache_dir=huggingface_cache_dir\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=huggingface_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(device))\n",
    "print(\"Memory Usage:\", torch.cuda.memory_allocated(device) / 1024 ** 3, \"GB\")\n",
    "print(\"Max Memory Usage:\", torch.cuda.max_memory_allocated(device) / 1024 ** 3, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=0.5,  # 'randomness' of outputs, 0.0 is not possible, so use a very small number\n",
    "    max_new_tokens=512,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  \n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_extract_to_dataframe(strings):\n",
    "    # Initialize empty lists to store extracted values\n",
    "    article_ids = []\n",
    "    about_covid_values = []\n",
    "\n",
    "    # Define regex pattern for article_id and about_covid with optional double quotes\n",
    "    article_id_pattern = r'\"article_id\"\\s*:\\s*\"?(\\d+)\"?'\n",
    "    about_covid_pattern = r'\"about_covid\"\\s*:\\s*\"?(\\d)\"?'\n",
    "\n",
    "    # Iterate through each string\n",
    "    for string_data in strings:\n",
    "        # Use regex to find matches for article_id\n",
    "        article_id_match = re.search(article_id_pattern, string_data)\n",
    "\n",
    "        # Use regex to find matches for about_covid\n",
    "        about_covid_match = re.search(about_covid_pattern, string_data)\n",
    "\n",
    "        # Extract values from the regex matches\n",
    "        article_id = int(article_id_match.group(1)) if article_id_match else None\n",
    "        about_covid = int(about_covid_match.group(1)) if about_covid_match else None\n",
    "\n",
    "        # Append values to the respective lists\n",
    "        article_ids.append(article_id)\n",
    "        about_covid_values.append(about_covid)\n",
    "\n",
    "    # Create a DataFrame using the extracted values\n",
    "    df = pd.DataFrame({\n",
    "        \"article_id\": article_ids,\n",
    "        \"about_covid\": about_covid_values\n",
    "    })\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_prompt_messages(system_prompt, input_prompt, main_prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": input_prompt + \"\\n\" + main_prompt},\n",
    "    ]\n",
    "    prompt = generate_text.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_prompt_messages(system_prompt, input_prompt, main_prompt, examples):\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    for user_prompt, assistant_prompt in examples:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_prompt + \"\\n\"})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": input_prompt + \"\\n\" + main_prompt})\n",
    "\n",
    "    prompt = generate_text.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Annotated NOS Articles DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/nos_analysis/nos_llm_analysis_final.csv',\n",
    "                 sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "# change article_id to integer\n",
    "df['article_id'] = df['article_id'].astype(int)\n",
    "\n",
    "topic_vars = ['about_covid',  'topic_a', 'topic_b', 'topic_c', 'topic_d', 'topic_e', 'topic_f', 'topic_g', 'topic_h', \n",
    "              'topic_i', 'topic_j', 'topic_k', 'topic_l', 'topic_m', 'topic_n', 'topic_o']\n",
    "\n",
    "# change all topic vars to int\n",
    "for i in topic_vars:\n",
    "    df[i] = df[i].astype(int)\n",
    "\n",
    "# remove line break\n",
    "df['Text'] = df['Text'].str.replace('[LINE_BREAK]', '\\n ')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there duplicate articles? \n",
    "duplicates = df[df.duplicated(subset=['article_id'], keep=False)]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Examples \n",
    "\n",
    "Randomly selected examples from the annotated dataset, that is not part of the dev or test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = pd.read_csv('data/nos_analysis/examples/about_covid.csv', sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "# change article_id to integer\n",
    "df_covid['article_id'] = df_covid['article_id'].astype(int)\n",
    "\n",
    "topic_vars = ['about_covid',  'topic_a', 'topic_b', 'topic_c', 'topic_d', 'topic_e', 'topic_f', 'topic_g', 'topic_h', \n",
    "              'topic_i', 'topic_j', 'topic_k', 'topic_l', 'topic_m', 'topic_n', 'topic_o']\n",
    "\n",
    "# change all topic vars to int\n",
    "for i in topic_vars:\n",
    "    df_covid[i] = df_covid[i].astype(int)\n",
    "\n",
    "# remove line break\n",
    "df_covid['Text'] = df_covid['Text'].str.replace('[LINE_BREAK]', '\\n ')\n",
    "\n",
    "print(df_covid.shape)\n",
    "\n",
    "\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_covid.article_id.value_counts())\n",
    "print(df_covid.Text.values)\n",
    "print(df_covid.Keywords.values)\n",
    "print(df_covid.Category.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_covid = pd.read_csv('data/nos_analysis/examples/not_covid.csv', sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "# change article_id to integer\n",
    "not_covid['article_id'] = not_covid['article_id'].astype(int)\n",
    "\n",
    "# change all topic vars to int\n",
    "for i in topic_vars:\n",
    "    not_covid[i] = not_covid[i].astype(int)\n",
    "\n",
    "# remove line break\n",
    "not_covid['Text'] = not_covid['Text'].str.replace('[LINE_BREAK]', '\\n ')\n",
    "\n",
    "print(not_covid.shape)\n",
    "not_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_covid.article_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(not_covid.article_id.value_counts())\n",
    "print(not_covid.Text.values)\n",
    "print(not_covid.Keywords.values)\n",
    "print(not_covid.Category.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "As a helpful AI assistant, your task is to determine the main topic of news articles. Articles may focus on either the \"Coronavirus and/or the COVID-19 pandemic\" or some other topic.\n",
    "A main topic is the overarching theme discussed in the majority of the news article. For an article to have the main topic of the \"Coronavirus and/or the COVID-19 pandemic\", it should predominantly discuss these subjects.\n",
    "\"\"\"\n",
    "\n",
    "input_prompt = \"\"\"\n",
    "Read the following article with the ID {article_id}: {text} \\n\n",
    "This article falls under the categories: {category} and contains the keywords: {keywords}.\n",
    "\"\"\"\n",
    "\n",
    "main_prompt = \"\"\"\n",
    "Take a moment to understand the article. \n",
    "Remember, for a topic to be a main topic of the news article, it should be discussed in the majority of the article. \n",
    "\n",
    "Based on the information provided, determine if the main topic of this news article is the \"Coronavirus and/or the COVID-19 pandemic\" or another subject. \n",
    "Assign a value of 1 if the main topic is the \"Coronavirus and/or the COVID-19 pandemic\", and a value of 0 if it is another subject.\n",
    "\n",
    "Output your results in JSON format with keys \"article_id\" and \"about_covid\", where the article ID and your answer are the values. \n",
    "Follow the example output format provided. Do not include any additional information or explanation. \\n\n",
    "\n",
    "Example Output (JSON format):\n",
    "{{\n",
    "    \"article_id\": \"2351150\",\n",
    "    \"about_covid\": \"1\"\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_example =[\n",
    "(\"\"\"\n",
    "Read the following article with the ID 2327099: 'Sinds gisteren zijn 155 nieuwe mensen positief getest op het coronavirus. Dat brengt het totaal op 959 patiënten, meldt het RIVM.\\n Er zijn twee nieuwe mensen aan de gevolgen van het virus overleden. Het gaat om ouderen met onderliggend lijden. In totaal staat het dodental in Nederland nu op twaalf.\\n Gisteren werden 190 nieuwe patiënten gemeld. Volgens het RIVM is de daling van vandaag het gevolg van het veranderde testbeleid.\\n \"Sinds 12 maart worden mensen met milde klachten niet meer getest omdat er een landelijke maatregel is om thuis te blijven bij de eerste klachten. Daarnaast wordt er meer getest onder risicogroepen\", zegt de instantie.\\n Op 12 maart riep de overheid Nederlanders op om sociale contacten te vermijden. Het is volgens het RIVM nog te vroeg om het effect daarvan te zien.\\n In het hele land was het vandaag op allerlei plekken veel rustiger dan anders op zaterdag:\\n De cijfers zeggen niet alles over het totale aantal besmettingen in Nederland. Alleen ernstig zieke mensen worden nog getest, zodat er voldoende testmateriaal voor riskante gevallen beschikbaar blijft. Daarnaast zijn er volgens de GGD waarschijnlijk veel mensen met milde klachten die thuis uitzieken en zich niet melden.' \\n\n",
    "This article falls under the categories: 'Binnenland' and contains the keywords: 'virus, besmettingen, RIVM, corona'.\n",
    "\n",
    "Take a moment to understand the article. \n",
    "Remember, for a topic to be a main topic of the news article, it should be discussed in the majority of the article. \n",
    "\n",
    "Based on the information provided, determine if the main topic of this news article is the \"Coronavirus and/or the COVID-19 pandemic\" or another subject. \n",
    "Assign a value of 1 if the main topic is the \"Coronavirus and/or the COVID-19 pandemic\", and a value of 0 if it is another subject.\n",
    "\n",
    "Output your results in JSON format with keys \"article_id\" and \"about_covid\", where the article ID and your answer are the values. \n",
    "Follow the example output format provided. Do not include any additional information or explanation. \\n\n",
    "\n",
    "Example Output (JSON format):\n",
    "{{\n",
    "    \"article_id\": \"2351150\",\n",
    "    \"about_covid\": \"1\"\n",
    "}}\n",
    "\"\"\", \n",
    "\"\"\"\n",
    "{{\n",
    "    \"article_id\": \"2327099\",\n",
    "    \"about_covid\": \"1\"\n",
    "}}\n",
    "\"\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_examples = [\n",
    "(\"\"\"\n",
    "Read the following article with the ID 2327099: 'Sinds gisteren zijn 155 nieuwe mensen positief getest op het coronavirus. Dat brengt het totaal op 959 patiënten, meldt het RIVM.\\n Er zijn twee nieuwe mensen aan de gevolgen van het virus overleden. Het gaat om ouderen met onderliggend lijden. In totaal staat het dodental in Nederland nu op twaalf.\\n Gisteren werden 190 nieuwe patiënten gemeld. Volgens het RIVM is de daling van vandaag het gevolg van het veranderde testbeleid.\\n \"Sinds 12 maart worden mensen met milde klachten niet meer getest omdat er een landelijke maatregel is om thuis te blijven bij de eerste klachten. Daarnaast wordt er meer getest onder risicogroepen\", zegt de instantie.\\n Op 12 maart riep de overheid Nederlanders op om sociale contacten te vermijden. Het is volgens het RIVM nog te vroeg om het effect daarvan te zien.\\n In het hele land was het vandaag op allerlei plekken veel rustiger dan anders op zaterdag:\\n De cijfers zeggen niet alles over het totale aantal besmettingen in Nederland. Alleen ernstig zieke mensen worden nog getest, zodat er voldoende testmateriaal voor riskante gevallen beschikbaar blijft. Daarnaast zijn er volgens de GGD waarschijnlijk veel mensen met milde klachten die thuis uitzieken en zich niet melden.' \\n\n",
    "This article falls under the categories: 'Binnenland' and contains the keywords: 'virus, besmettingen, RIVM, corona'.\n",
    "\n",
    "Take a moment to understand the article. \n",
    "Remember, for a topic to be a main topic of the news article, it should be discussed in the majority of the article. \n",
    "\n",
    "Based on the information provided, determine if the main topic of this news article is the \"Coronavirus and/or the COVID-19 pandemic\" or another subject. \n",
    "Assign a value of 1 if the main topic is the \"Coronavirus and/or the COVID-19 pandemic\", and a value of 0 if it is another subject.\n",
    "\n",
    "Output your results in JSON format with keys \"article_id\" and \"about_covid\", where the article ID and your answer are the values. \n",
    "Follow the example output format provided. Do not include any additional information or explanation. \\n\n",
    "\n",
    "Example Output (JSON format):\n",
    "{{\n",
    "    \"article_id\": \"2351150\",\n",
    "    \"about_covid\": \"1\"\n",
    "}}\n",
    "\"\"\", \n",
    "\"\"\"\n",
    "{{\n",
    "    \"article_id\": \"2327099\",\n",
    "    \"about_covid\": \"1\"\n",
    "}}\n",
    "\"\"\"),\n",
    "(\"\"\"\n",
    "Read the article with ID 2446472: 'De wachtrijen in de langdurige zorg zijn in juli fors gestegen. De toename was afgelopen jaar niet eerder zo groot, meldt de Nederlandse Zorgautoriteit (NZa) in haar maandelijkse overzicht.\\n Het aantal mensen dat moet wachten op zorg vanuit de Wet langdurige zorg (Wlz) steeg van 21.653 op 1 juli naar 23.497 in augustus. De toename deed zich voor in alle drie de sectoren: verpleeg- en verzorgingstehuizen, gehandicaptenzorg en langdurige geestelijke gezondheidszorg. De NZa weet geen oorzaak voor de plotselinge stijging.\\n De afgelopen tijd is het ook veel gegaan over het ziekteverzuim in de zorg. De NZa ziet dat die nog steeds in alle sectoren hoog is, maar er is nu wel een lichte daling zichtbaar in het kortdurend ziekteverzuim.\\n Het langdurige ziekteverzuim is gelijk gebleven. Het ziekteverzuim in combinatie met personeelstekorten baart de zorgtoezichthouder zorgen, met name in de langdurige zorg. Er zijn vaak genoeg bedden beschikbaar, maar er is niet altijd genoeg personeel om de langdurige zorg te leveren.' \\n\n",
    "This article falls under the categories: 'Binnenland' and contains the keywords: 'verpleeg- en verzorgingshuizen, Wet Langdurige Zorg, langdurige zorg, ziekenhuiszorg'.\n",
    "\n",
    "Take a moment to understand the article. \n",
    "Remember, for a topic to be a main topic of the news article, it should be discussed in the majority of the article. \n",
    "\n",
    "Based on the information provided, determine if the main topic of this news article is the \"Coronavirus and/or the COVID-19 pandemic\" or another subject. \n",
    "Assign a value of 1 if the main topic is the \"Coronavirus and/or the COVID-19 pandemic\", and a value of 0 if it is another subject.\n",
    "\n",
    "Output your results in JSON format with keys \"article_id\" and \"about_covid\", where the article ID and your answer are the values. \n",
    "Follow the example output format provided. Do not include any additional information or explanation. \\n\n",
    "\n",
    "Example Output (JSON format):\n",
    "{{\n",
    "    \"article_id\": \"2351150\",\n",
    "    \"about_covid\": \"1\"\n",
    "}}\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "{{\n",
    "    \"article_id\": \"2446472\",\n",
    "    \"about_covid\": \"0\"\n",
    "}}\n",
    "\"\"\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_covid[not_covid['article_id'] == 2399596].Text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_covid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Covid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot Classifier About_Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompt = zero_shot_prompt_messages(system_prompt, input_prompt, main_prompt)\n",
    "print(zero_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"article_id\", \"text\", \"category\", \"keywords\"],\n",
    "    template=zero_shot_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one = LLMChain(llm = llm, prompt = prompt_template, output_key=\"article_id, about_covid\")\n",
    "chain_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text_zeroshot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "torch.manual_seed(0)\n",
    "\n",
    "for index, row in df.iterrows():  \n",
    "    article_id = row['article_id']\n",
    "    text = row['Text']\n",
    "    category = row['Category']\n",
    "    keywords = row['Keywords']\n",
    "\n",
    "\n",
    "    input_variables = {\n",
    "            \"article_id\": article_id,\n",
    "            \"text\": text,\n",
    "            \"category\": category,\n",
    "            \"keywords\": keywords\n",
    "        }\n",
    "    # Generate text using the chain\n",
    "    generated_text = chain_one.run(input_variables)\n",
    "    print(generated_text)\n",
    "    generated_text_zeroshot.append(generated_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text_zeroshot[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = regex_extract_to_dataframe(generated_text_zeroshot)\n",
    "\n",
    "print(len(json_list))\n",
    "df_zeroshot = pd.DataFrame(json_list)\n",
    "print(len(df_zeroshot))\n",
    "df_zeroshot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zeroshot['about_covid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename about_covid to about_covid_pred\n",
    "df_zeroshot = df_zeroshot.rename(columns={'about_covid': 'about_covid_pred'})\n",
    "df_zeroshot['article_id'] = df_zeroshot['article_id'].astype(int)\n",
    "df_zeroshot['about_covid_pred'] = df_zeroshot['about_covid_pred'].astype(int)\n",
    "\n",
    "df_zeroshot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get real article_id and about_covid\n",
    "df_coded = df[['article_id', 'about_covid']]\n",
    "df_coded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "df_zeroshot_merged = pd.merge(df_coded, df_zeroshot, how='left', on=\"article_id\")\n",
    "print(len(df_zeroshot_merged))\n",
    "df_zeroshot_merged.head()\n",
    "\n",
    "# make pred int\n",
    "# drop nan\n",
    "df_zeroshot_merged = df_zeroshot_merged.dropna()\n",
    "df_zeroshot_merged['about_covid_pred'] = df_zeroshot_merged['about_covid_pred'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_zeroshot_merged['about_covid'], df_zeroshot_merged['about_covid_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_zeroshot_merged['about_covid'], df_zeroshot_merged['about_covid_pred']))\n",
    "print(\"Cohen's Kappa:\", cohen_kappa_score(df_zeroshot_merged['about_covid'], df_zeroshot_merged['about_covid_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write df to results \n",
    "df_zeroshot_merged.to_csv('data/nos_analysis/results/about_covid_starling_zeroshot_v4.csv', sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change df shape wher\n",
    "humancoded = df_zeroshot_merged[['article_id', 'about_covid']]\n",
    "humancoded['coder']='human'\n",
    "humancoded\n",
    "machinecoded = df_zeroshot_merged[['article_id', 'about_covid_pred']]\n",
    "machinecoded['coder']='machine'\n",
    "machinecoded.rename(columns={'about_covid_pred': 'about_covid'}, inplace=True)\n",
    "\n",
    "df_zeroshot_merged_krip = pd.concat([humancoded, machinecoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_krip = simpledorff.calculate_krippendorffs_alpha_for_df(df_zeroshot_merged_krip,experiment_col='article_id',\n",
    "                                                 annotator_col='coder',\n",
    "                                                 class_col='about_covid')\n",
    "\n",
    "print(\"Krippendorff's Alpha:\", zeroshot_krip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Shot Classifier About_Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_prompt = few_shot_prompt_messages(system_prompt, input_prompt, main_prompt, one_shot_example)\n",
    "print(one_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"article_id\", \"text\", \"category\", \"keywords\"],\n",
    "    template=one_shot_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_2 = LLMChain(llm = llm, prompt = prompt_template, output_key=\"article_id, about_covid\")\n",
    "chain_2         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text_oneshot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "torch.manual_seed(0)\n",
    "for index, row in df.iterrows():  \n",
    "    article_id = row['article_id']\n",
    "    text = row['Text']\n",
    "    category = row['Category']\n",
    "    keywords = row['Keywords']\n",
    "\n",
    "\n",
    "    input_variables = {\n",
    "            \"article_id\": article_id,\n",
    "            \"text\": text,\n",
    "            \"category\": category,\n",
    "            \"keywords\": keywords\n",
    "        }\n",
    "    # Generate text using the chain\n",
    "    generated_text = chain_2.run(input_variables)\n",
    "    generated_text_oneshot.append(generated_text)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text_oneshot[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = regex_extract_to_dataframe(generated_text_oneshot)\n",
    "\n",
    "print(len(json_list))\n",
    "df_oneshot = pd.DataFrame(json_list)\n",
    "print(len(df_oneshot))\n",
    "df_oneshot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oneshot['about_covid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename about_covid to about_covid_pred\n",
    "df_oneshot = df_oneshot.rename(columns={'about_covid': 'about_covid_pred'})\n",
    "\n",
    "df_oneshot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change article_id to int\n",
    "df_oneshot['article_id'] = df_oneshot['article_id'].astype(int)\n",
    "df_coded['article_id'] = df_coded['article_id'].astype(int)\n",
    "\n",
    "df_oneshot['about_covid_pred'] = df_oneshot['about_covid_pred'].astype(int)\n",
    "df_coded['about_covid'] = df_coded['about_covid'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get real article_id and about_covid\n",
    "df_coded = df[['article_id', 'about_covid']]\n",
    "df_coded.head()\n",
    "\n",
    "# merge df_zeroshot_v2 with df on index\n",
    "df_oneshot_merged = pd.merge(df_coded, df_oneshot, how='left', on=\"article_id\")\n",
    "print(len(df_oneshot_merged))\n",
    "df_oneshot_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_oneshot_merged['about_covid'], df_oneshot_merged['about_covid_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_oneshot_merged['about_covid'], df_oneshot_merged['about_covid_pred']))\n",
    "print(\"Cohen's Kappa:\", cohen_kappa_score(df_oneshot_merged['about_covid'], df_oneshot_merged['about_covid_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change df shape wher\n",
    "humancoded = df_oneshot_merged[['article_id', 'about_covid']]\n",
    "humancoded['coder']='human'\n",
    "humancoded\n",
    "machinecoded = df_oneshot_merged[['article_id', 'about_covid_pred']]\n",
    "machinecoded['coder']='machine'\n",
    "machinecoded.rename(columns={'about_covid_pred': 'about_covid'}, inplace=True)\n",
    "\n",
    "df_oneshot_merged_krip = pd.concat([humancoded, machinecoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneshot_krip = simpledorff.calculate_krippendorffs_alpha_for_df(df_oneshot_merged_krip,experiment_col='article_id',\n",
    "                                                 annotator_col='coder',\n",
    "                                                 class_col='about_covid')\n",
    "\n",
    "print(\"Krippendorff's Alpha:\", oneshot_krip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write df to results \n",
    "df_oneshot_merged.to_csv('data/nos_analysis/results/about_covid_starling_oneshot_v4.csv', sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot Classifier About_Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = few_shot_prompt_messages(system_prompt, input_prompt, main_prompt, few_shot_examples)\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"article_id\", \"text\", \"category\", \"keywords\"],\n",
    "    template=few_shot_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_3 = LLMChain(llm = llm, prompt = prompt_template, output_key=\"article_id, about_covid\")\n",
    "chain_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text_fewshot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "torch.manual_seed(0)\n",
    "for index, row in df.iterrows():  \n",
    "    article_id = row['article_id']\n",
    "    text = row['Text']\n",
    "    category = row['Category']\n",
    "    keywords = row['Keywords']\n",
    "\n",
    "\n",
    "    input_variables = {\n",
    "            \"article_id\": article_id,\n",
    "            \"text\": text,\n",
    "            \"category\": category,\n",
    "            \"keywords\": keywords\n",
    "        }\n",
    "    # Generate text using the chain\n",
    "    generated_text = chain_3.run(input_variables)\n",
    "    generated_text_fewshot.append(generated_text)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text_fewshot[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = regex_extract_to_dataframe(generated_text_fewshot)\n",
    "\n",
    "print(len(json_list))\n",
    "df_fewshot = pd.DataFrame(json_list)\n",
    "print(len(df_fewshot))\n",
    "df_fewshot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fewshot['about_covid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename about_covid to about_covid_pred\n",
    "df_fewshot = df_fewshot.rename(columns={'about_covid': 'about_covid_pred'})\n",
    "\n",
    "df_fewshot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get real article_id and about_covid\n",
    "df_coded = df[['article_id', 'about_covid']]\n",
    "df_coded.head()\n",
    "\n",
    "# merge df_zeroshot_v2 with df on index\n",
    "df_fewshot_merged = pd.merge(df_coded, df_fewshot, how='left', on=\"article_id\")\n",
    "print(len(df_fewshot_merged))\n",
    "df_fewshot_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there nan\n",
    "df_fewshot_merged.isnull().sum()\n",
    "\n",
    "# drop if about_covid_pred is null\n",
    "df_fewshot_merged=df_fewshot_merged[df_fewshot_merged['about_covid_pred'].notnull()]\n",
    "df_fewshot_merged['about_covid_pred'] = df_fewshot_merged['about_covid_pred'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_fewshot_merged['about_covid'], df_fewshot_merged['about_covid_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_fewshot_merged['about_covid'], df_fewshot_merged['about_covid_pred']))\n",
    "print(\"Cohen's Kappa:\", cohen_kappa_score(df_fewshot_merged['about_covid'], df_fewshot_merged['about_covid_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change df shape wher\n",
    "humancoded = df_fewshot_merged[['article_id', 'about_covid']]\n",
    "humancoded['coder']='human'\n",
    "humancoded\n",
    "machinecoded = df_fewshot_merged[['article_id', 'about_covid_pred']]\n",
    "machinecoded['coder']='machine'\n",
    "machinecoded.rename(columns={'about_covid_pred': 'about_covid'}, inplace=True)\n",
    "\n",
    "df_fewshot_merged_krip = pd.concat([humancoded, machinecoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_krip = simpledorff.calculate_krippendorffs_alpha_for_df(df_fewshot_merged_krip,experiment_col='article_id',\n",
    "                                                 annotator_col='coder',\n",
    "                                                 class_col='about_covid')\n",
    "\n",
    "print(\"Krippendorff's Alpha:\", fewshot_krip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write df to results \n",
    "df_fewshot_merged.to_csv('data/nos_analysis/results/about_covid_starling_fewshot_v4.csv', sep = ';', encoding = 'utf-8', quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "llmkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
